{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6611b61-ea4a-4a03-8ed9-2c9408f99709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import AutoEncoder\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torchaudio.transforms as T\n",
    "import Dataset\n",
    "from lib.AudioSet.transform import TimeSequenceLengthFixer, SoundTrackSelector\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import DataTransform\n",
    "\n",
    "import lib.MuxkitDeepLearningTools.dataset_tools.CachableDataset as mk_cachedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30f9b1cb-d38f-427a-a3d0-30773ca92c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToDevice(nn.Module):\n",
    "    def __init__(self, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "        self.device = \"cuda\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.to(self.device)\n",
    "\n",
    "with open(\"hyperpara.yml\", \"r\") as f:\n",
    "    hyper_parameter = yaml.safe_load(f)\n",
    "Device = hyper_parameter[\"TrainProcessControl\"][\"device\"]\n",
    "\n",
    "pipeline = nn.Sequential(\n",
    "    SoundTrackSelector(hyper_parameter[\"SoundTrackSelector\"]['mode']),\n",
    "    ToDevice(Device),\n",
    "    T.Resample(**hyper_parameter[\"Resample\"]),\n",
    "    TimeSequenceLengthFixer(**hyper_parameter[\"TimeSequenceLengthFixer\"]),\n",
    "    DataTransform.ToLogMelSpectrogram(**hyper_parameter[\"ToLogMelSpectrogram\"]),\n",
    ").to(Device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def data_preprocess(x: torch.Tensor)->torch.Tensor:\n",
    "    return pipeline(x)\n",
    "with open(\"other_configs.yml\", \"r\") as f:\n",
    "    trainset, evalset = Dataset.AudioSet.from_yaml(yaml.safe_load(f))\n",
    "trainset.transform=data_preprocess\n",
    "evalset.transform=data_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da2c9dc2-e19c-4e4f-9f6b-93008413e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder.AutoEncoder(**hyper_parameter[\"AutoEncoder\"]).to(Device)\n",
    "# from torchinfo import summary\n",
    "# summary(model, input_size=trainset[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7e447e0-14d3-4fa8-90d3-471109a69a0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                       lr=float(hyper_parameter[\"TrainProcessControl\"][\"LearningRate\"]),\n",
    "                       weight_decay=float(hyper_parameter[\"TrainProcessControl\"][\"Optimizer\"][\"WeightDecay\"]))\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    patience=hyper_parameter[\"TrainProcessControl\"][\"Scheduler\"][\"patience\"],\n",
    ")\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "train_losses = torch.empty(0).to(Device)\n",
    "validate_losses = torch.empty(0).to(Device)\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "subset_size = 1000\n",
    "val_test_split = 500\n",
    "\n",
    "subset = torch.utils.data.Subset(evalset, torch.randperm(len(evalset))[:subset_size].tolist())\n",
    "validate_set, test_set = random_split(subset, [val_test_split, subset_size - val_test_split])\n",
    "trainset = mk_cachedata.CacheableDataset(trainset, **hyper_parameter[\"CacheableDataset\"])\n",
    "validate_set = mk_cachedata.CacheableDataset(validate_set, **hyper_parameter[\"CacheableDataset\"])\n",
    "test_set = mk_cachedata.CacheableDataset(test_set, **hyper_parameter[\"CacheableDataset\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35f1627e-74a8-4524-8bc7-f8fd6d0a0a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_loss(x, x_hat):\n",
    "    return loss_function(x, x_hat)\n",
    "def one_epoch(dataloader, loss_save_to: torch.Tensor):\n",
    "    for batch in dataloader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_hat = model(batch)\n",
    "        loss = one_step_loss(batch, x_hat)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_losses.append(loss.item())\n",
    "\n",
    "    # log mean loss for the epoch\n",
    "    mean_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "    loss_tensor = torch.tensor([mean_loss], device=loss_save_to.device)\n",
    "    loss_save_to = torch.cat([loss_save_to, loss_tensor])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0505bd50-cced-4eb9-8299-8ae3a0f77859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch=None, save_dir=\"./checkpoints\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    filename = f\"checkpoint_{now}.pt\"\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, save_path)\n",
    "\n",
    "    print(f\"[âœ“] Checkpoint saved: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8142b1-cae9-4b9e-9e2e-7b499f47cdc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
